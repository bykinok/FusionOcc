"""
Layer-by-Layer Comparison Utility
ê° ëª¨ë“ˆì˜ ì…ë ¥/ì¶œë ¥ì„ ìƒì„¸íˆ ê¸°ë¡í•˜ì—¬ ì›ë³¸ê³¼ ë¹„êµ
"""
import json
import torch
import numpy as np
from pathlib import Path


class LayerDebugger:
    """ë ˆì´ì–´ë³„ ë””ë²„ê·¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, save_dir="debug_outputs"):
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True, parents=True)
        self.stats = {}
        self.sample_idx = 0
        
    def set_sample_idx(self, idx):
        """í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìƒ˜í”Œ ì¸ë±ìŠ¤ ì„¤ì •"""
        self.sample_idx = idx
        
    def compute_tensor_stats(self, tensor, name):
        """í…ì„œì˜ ìƒì„¸ í†µê³„ ê³„ì‚°"""
        if tensor is None:
            return {"type": "None"}
            
        if not isinstance(tensor, torch.Tensor):
            return {"type": str(type(tensor))}
        
        # Move to CPU for computation
        t = tensor.detach().cpu().float()
        
        stats = {
            "shape": list(t.shape),
            "dtype": str(tensor.dtype),
            "device": str(tensor.device),
            "mean": float(t.mean()),
            "std": float(t.std()),
            "min": float(t.min()),
            "max": float(t.max()),
            "abs_mean": float(t.abs().mean()),
            "abs_max": float(t.abs().max()),
        }
        
        # Non-zero ratio
        stats["non_zero_ratio"] = float((t != 0).float().mean())
        
        # Negative ratio
        stats["negative_ratio"] = float((t < 0).float().mean())
        
        # Percentiles
        flat = t.flatten()
        if flat.numel() > 0:
            percentiles = [0, 1, 5, 25, 50, 75, 95, 99, 100]
            percentile_vals = np.percentile(flat.numpy(), percentiles)
            stats["percentiles"] = {f"p{p}": float(v) for p, v in zip(percentiles, percentile_vals)}
        
        # Histogram (10 bins)
        hist, bin_edges = np.histogram(flat.numpy(), bins=10)
        stats["histogram"] = {
            "counts": hist.tolist(),
            "bin_edges": bin_edges.tolist()
        }
        
        return stats
    
    def log_module_io(self, module_name, input_tensors=None, output_tensors=None, 
                      extra_info=None, save=True):
        """ëª¨ë“ˆì˜ ì…ì¶œë ¥ ì •ë³´ ê¸°ë¡
        
        Args:
            module_name: ëª¨ë“ˆ ì´ë¦„ (ì˜ˆ: "image_backbone", "depthnet", "voxel_pooling")
            input_tensors: ì…ë ¥ í…ì„œ dict
            output_tensors: ì¶œë ¥ í…ì„œ dict
            extra_info: ì¶”ê°€ ì •ë³´ dict
            save: ì¦‰ì‹œ ì €ì¥í• ì§€ ì—¬ë¶€
        """
        entry = {
            "sample_idx": self.sample_idx,
            "module": module_name,
            "inputs": {},
            "outputs": {},
            "extra": extra_info or {}
        }
        
        # Process inputs
        if input_tensors:
            for key, tensor in input_tensors.items():
                if isinstance(tensor, (list, tuple)):
                    entry["inputs"][key] = [
                        self.compute_tensor_stats(t, f"{key}_{i}") 
                        for i, t in enumerate(tensor)
                    ]
                else:
                    entry["inputs"][key] = self.compute_tensor_stats(tensor, key)
        
        # Process outputs
        if output_tensors:
            for key, tensor in output_tensors.items():
                if isinstance(tensor, (list, tuple)):
                    entry["outputs"][key] = [
                        self.compute_tensor_stats(t, f"{key}_{i}") 
                        for i, t in enumerate(tensor)
                    ]
                else:
                    entry["outputs"][key] = self.compute_tensor_stats(tensor, key)
        
        # Store in memory
        if module_name not in self.stats:
            self.stats[module_name] = []
        self.stats[module_name].append(entry)
        
        # Save to file if requested
        if save:
            self.save_stats(module_name)
        
        return entry
    
    def log_weights(self, module_name, model, save=True):
        """ëª¨ë¸ì˜ weight í†µê³„ ê¸°ë¡"""
        weights_stats = {}
        
        for name, param in model.named_parameters():
            if param.requires_grad:
                weights_stats[name] = self.compute_tensor_stats(param.data, name)
        
        entry = {
            "sample_idx": self.sample_idx,
            "module": module_name,
            "weights": weights_stats
        }
        
        # Store in memory
        weight_key = f"{module_name}_weights"
        if weight_key not in self.stats:
            self.stats[weight_key] = []
        self.stats[weight_key].append(entry)
        
        # Save to file if requested
        if save:
            self.save_stats(weight_key)
        
        return entry
    
    def save_stats(self, module_name=None):
        """í†µê³„ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            module_name: íŠ¹ì • ëª¨ë“ˆë§Œ ì €ì¥ (Noneì´ë©´ ì „ì²´ ì €ì¥)
        """
        if module_name:
            # Save specific module
            if module_name in self.stats:
                filepath = self.save_dir / f"{module_name}_sample{self.sample_idx}.json"
                with open(filepath, 'w') as f:
                    json.dump(self.stats[module_name], f, indent=2)
        else:
            # Save all
            for key, data in self.stats.items():
                filepath = self.save_dir / f"{key}_sample{self.sample_idx}.json"
                with open(filepath, 'w') as f:
                    json.dump(data, f, indent=2)
    
    def compare_with_reference(self, module_name, reference_file):
        """ì›ë³¸ ëª¨ë¸ì˜ ì¶œë ¥ê³¼ ë¹„êµ
        
        Args:
            module_name: ë¹„êµí•  ëª¨ë“ˆ ì´ë¦„
            reference_file: ì›ë³¸ ì¶œë ¥ì´ ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ë¹„êµ ê²°ê³¼ dict
        """
        # Load reference
        with open(reference_file, 'r') as f:
            reference = json.load(f)
        
        # Get current stats
        if module_name not in self.stats or len(self.stats[module_name]) == 0:
            return {"error": "No current stats available"}
        
        current = self.stats[module_name][-1]
        
        # Compare
        comparison = {
            "module": module_name,
            "differences": {}
        }
        
        # Compare outputs
        for key in current.get("outputs", {}).keys():
            if key in reference.get("outputs", {}):
                curr_stats = current["outputs"][key]
                ref_stats = reference["outputs"][key]
                
                if isinstance(curr_stats, dict) and isinstance(ref_stats, dict):
                    diff = {
                        "mean_diff": curr_stats.get("mean", 0) - ref_stats.get("mean", 0),
                        "std_diff": curr_stats.get("std", 0) - ref_stats.get("std", 0),
                        "mean_ratio": curr_stats.get("mean", 0) / (ref_stats.get("mean", 0) + 1e-10),
                        "max_diff": curr_stats.get("max", 0) - ref_stats.get("max", 0),
                        "min_diff": curr_stats.get("min", 0) - ref_stats.get("min", 0),
                    }
                    comparison["differences"][key] = diff
        
        return comparison
    
    def print_summary(self, module_name):
        """ëª¨ë“ˆì˜ í†µê³„ ìš”ì•½ ì¶œë ¥"""
        if module_name not in self.stats or len(self.stats[module_name]) == 0:
            print(f"[{module_name}] No stats available")
            return
        
        entry = self.stats[module_name][-1]
        
        print(f"\n{'='*80}")
        print(f"[{module_name.upper()}] Summary - Sample {entry['sample_idx']}")
        print(f"{'='*80}")
        
        # Print inputs
        if entry.get("inputs"):
            print("\nğŸ“¥ INPUTS:")
            for key, stats in entry["inputs"].items():
                if isinstance(stats, list):
                    for i, s in enumerate(stats):
                        print(f"  [{key}_{i}] Shape: {s.get('shape')}, Mean: {s.get('mean', 0):.6f}, Std: {s.get('std', 0):.6f}")
                else:
                    print(f"  [{key}] Shape: {stats.get('shape')}, Mean: {stats.get('mean', 0):.6f}, Std: {stats.get('std', 0):.6f}")
        
        # Print outputs
        if entry.get("outputs"):
            print("\nğŸ“¤ OUTPUTS:")
            for key, stats in entry["outputs"].items():
                if isinstance(stats, list):
                    for i, s in enumerate(stats):
                        print(f"  [{key}_{i}] Shape: {s.get('shape')}, Mean: {s.get('mean', 0):.6f}, Std: {s.get('std', 0):.6f}")
                else:
                    print(f"  [{key}] Shape: {stats.get('shape')}, Mean: {stats.get('mean', 0):.6f}, Std: {stats.get('std', 0):.6f}")
                    print(f"         Range: [{stats.get('min', 0):.6f}, {stats.get('max', 0):.6f}]")
                    print(f"         Non-zero: {stats.get('non_zero_ratio', 0)*100:.2f}%, Negative: {stats.get('negative_ratio', 0)*100:.2f}%")
        
        # Print extra info
        if entry.get("extra"):
            print("\nğŸ“‹ EXTRA INFO:")
            for key, value in entry["extra"].items():
                print(f"  {key}: {value}")
        
        print(f"{'='*80}\n")


# Global debugger instance
global_debugger = None

def get_debugger(save_dir="debug_outputs"):
    """ì „ì—­ ë””ë²„ê±° ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global global_debugger
    if global_debugger is None:
        global_debugger = LayerDebugger(save_dir=save_dir)
    return global_debugger


def log_layer(module_name, inputs=None, outputs=None, extra=None, print_summary=False):
    """ë ˆì´ì–´ ì •ë³´ ë¡œê¹… (ê°„í¸ í•¨ìˆ˜)"""
    debugger = get_debugger()
    debugger.log_module_io(module_name, inputs, outputs, extra, save=True)
    
    if print_summary:
        debugger.print_summary(module_name)


def log_model_weights(module_name, model):
    """ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œê¹… (ê°„í¸ í•¨ìˆ˜)"""
    debugger = get_debugger()
    debugger.log_weights(module_name, model, save=True)

